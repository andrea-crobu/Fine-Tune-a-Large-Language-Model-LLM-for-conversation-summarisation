{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqdoJ2mkvLt5"
   },
   "source": [
    "# Phase 2: Model Training\n",
    "\n",
    "In this phase, we will fine-tune the Flan-T5 model using LoRA (Low-Rank Adaptation) to improve its performance for text summarization. We will use the HuggingFace Transformers library to set up the training pipeline.\n",
    "\n",
    "## Steps:\n",
    "\n",
    "1. **Load the Base Model**\n",
    "\n",
    "2. **Integrate LoRA for Fine-Tuning**\n",
    "\n",
    "3. **Configure the Training Pipeline**\n",
    "\n",
    "4. **Fine-Tune the Model**\n",
    "\n",
    "This phase focuses on leveraging parameter-efficient fine-tuning via LoRA to adapt the Flan-T5 model for improved summarization performance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35975,
     "status": "ok",
     "timestamp": 1739718849697,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "jCmcfhyMvLt8"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739718849698,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "LtFxHNckvLt-",
    "outputId": "965957d6-1d5d-438e-9352-805977ae83ec"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2-MXdaMvLt_"
   },
   "source": [
    "### Load the Flan-T5-base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ddb84e42e1904e76978970940f1cb5e4",
      "67730b2b1ebb400db77433537ff880aa",
      "e190de28504c4373809959933d678946",
      "324a4cdb46dd42c0a03028a06ecfa62f",
      "f5f4d44def7a4848a54e1a5eda3e8213",
      "0c7c8708ab7840bea8208d76027e3c1e",
      "60fde94046e5478a9f6a609db648efbd",
      "e7a783a8739d41e8a0bb0ca6f8a1e792",
      "03b7ef290cb640c4a7e756112e2e0270",
      "26de8d179b714654be478364cdcc73d6",
      "ba8776824e58448f99af672af327cdab",
      "fb08787f39ca430b9c4e7656bdc1900c",
      "15e086f85a814dfc9cfceb1b4989d77d",
      "9d25d1fa18444f42a1456c6926162dfb",
      "2fffaac649d4442dbb8d3a99128d0d1b",
      "f198a185c675436f8a2852ebdfa109a1",
      "c991ab0cd6b743659b608f13102ac9ec",
      "e429dad09ef24536a93d208fd9332e01",
      "e3e8eb5812384d62b94f3b7dc5e246a4",
      "8d83e610d7e445babcddedd4a8eb45ce",
      "1c46c3934d6d44ad9aa8f5f6dfacb700",
      "fd6a8561ba994f8da46d98de6a77652e",
      "51e773147be84c04937a9f44061b9d4d",
      "5d0e4722103c43a493070d94ea514f8c",
      "02ddb29171074dc797291eaf3c4023ec",
      "bfc803ff8790412f8033b0d2221db623",
      "11d377145ada4f7784a64af698208f6e",
      "6d52a08a4b2646b2b1e8a6b541fecf2e",
      "1edaeffe54dd48c6bb8d768a33dcdb40",
      "94af83dad5784fcebcafa7b063c9e9d4",
      "c01bfe19a21a475daeb9c564abdee66f",
      "41998603ffe8461f89f5d32a33d1283e",
      "09d22cd2331349e4a42e55f7311725b7"
     ]
    },
    "executionInfo": {
     "elapsed": 9207,
     "status": "ok",
     "timestamp": 1739718861794,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "xdP-A56vvLt_",
    "outputId": "8c71e966-a856-4cdd-bcec-fac35d6d5abf"
   },
   "outputs": [],
   "source": [
    "model_name='google/flan-t5-base'\n",
    "\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "base_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jOZFGDivLt_"
   },
   "source": [
    "### Define the tokenizer, to decode the output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "f53bf5d5eee24a47b77c0f57894a14e0",
      "ee98577120224201a90b5c38af4e5de6",
      "ddcb1f17b0f34ecf812d1a7c6259bad6",
      "80d98e96c6fd4b11bc8c2a74a7f4d3ff",
      "2549d1d91d5644709e98fb6a04d161dd",
      "d9ed51a9ee7445eab4bf7484fdcbb50c",
      "d4cd1442f4674a65b6acae10407faffa",
      "7d752742fb4142fa9339c7bff272a028",
      "69288d504a0d49e1a2da9b58ae94fce6",
      "c5fe47c816694ed1a554236017d21dda",
      "6af8adde4b854fc2ad1cc70809b62d5f",
      "8d1701af0ccd4a158b6812f5239134d1",
      "77a0c99c7a22450faef677704f872d39",
      "abf03d37dda1431a84389889c0d06c4f",
      "533e5fadcd2741418557c477b08c5f0a",
      "d6830e45e91641e9b76fcf76cb42a4c1",
      "e7a34dbf7e044e9091967b1b88efc0c6",
      "4def0474df8b4d15ba843398337f7a8f",
      "8f8d256c58d7485eabda5fa4c071e6c9",
      "5cf05b53323d494fa33ba0429114d97b",
      "d9ffeb1c0a464f6195f6d00489a22f69",
      "81866bc1f1124ccfbb947888d3fac2a0",
      "f9dd4f15ad5b484abce5e74eef5392fe",
      "883a27a825dd4dc3b17f78ec2e82a5a6",
      "49deac17461a4d7bac49b536472147c7",
      "a138f8af532941b3b7c157b8e6aa18f4",
      "d03596a81c2840ba958c072bed59dce8",
      "fbbbe1e98f1a47b493983d724f6421bf",
      "76268ff8e50646fc841840f3184ebee8",
      "18ed66c2a1e04b9da4c01685dacc84b7",
      "ad59d87a6d3741b4be8aa17912109e5e",
      "72dcd6b22e5345c88a6a6ceb632d2c2b",
      "de35ffb5c49e4ce794881f00cbf71192",
      "79b1a9d1e2f64086ae73de035cc8478d",
      "ca067a9a54794adfb517c88e7446e690",
      "d4c7a58dcb3f44df9e8d826b1feead0e",
      "8f1764e984a14c8d869aa94fdaedf1d5",
      "4eabd5d49fc2473693194cdf69347d66",
      "74890250690f4a1c8b53bfd826508bac",
      "d343a523318648bba11a910c4bd93bfb",
      "d1e4c6564a3a44b9921a10689cf8f5ea",
      "3c94f295a1524435bdb6e9d5ff70f4a2",
      "94fe61a0cb5a44aa8f40b8938089160f",
      "5f99508d8322498a8bf0ea1f514d7b37"
     ]
    },
    "executionInfo": {
     "elapsed": 3143,
     "status": "ok",
     "timestamp": 1739718864928,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "wgLXV8vovLt_",
    "outputId": "0fd88141-8b58-4297-c36a-a5190b28316e"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amF8Az_tvLuA"
   },
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3821,
     "status": "ok",
     "timestamp": 1739718916853,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "4HoL1d8vvLuA"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/dataset_t5_base.pkl', 'rb') as file:\n",
    "    dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nam9ZvEVvLuA"
   },
   "source": [
    "### Setup the PEFT configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1739719054479,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "t7Xk530gvLuA"
   },
   "outputs": [],
   "source": [
    "# Set up LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=24,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\"\n",
    ")\n",
    "\n",
    "# Wrap model with LoRA\n",
    "peft_model = get_peft_model(base_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1059,
     "status": "ok",
     "timestamp": 1739719057935,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "6q9AucWK5Yyy"
   },
   "outputs": [],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739719058330,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "bK92eyUv5Rj3",
    "outputId": "98489d6d-a6ab-4e51-c873-e8d738dba317"
   },
   "outputs": [],
   "source": [
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bnBXYdKvLuB"
   },
   "source": [
    "### Create the data collator, set the training parameters and create the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 452,
     "status": "ok",
     "timestamp": 1739719063424,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "M6S9yFnmvLuB"
   },
   "outputs": [],
   "source": [
    "# Define the data collator to handle padding dynamically. For the moment, the dataset is composed of lists of variable lenght.\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dh9-X1N8vLuB"
   },
   "outputs": [],
   "source": [
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_training\",\n",
    "    report_to=\"none\",  # Disable logging to W&B\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1739719068510,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "g61VKs_JAsfX"
   },
   "outputs": [],
   "source": [
    "# Get LoRA trainable parameters\n",
    "lora_parameters = [p for p in peft_model.parameters() if p.requires_grad]\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.AdamW(lora_parameters, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHWuG-JtvLuB"
   },
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    optimizers=(optimizer, None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izO3d2H1VwwM"
   },
   "outputs": [],
   "source": [
    "# Start fine-tuning\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t23tYgT142zg"
   },
   "outputs": [],
   "source": [
    "model_path=\"./peft_model_trained_google_flan_t5_base_dialogue_summarization\"\n",
    "\n",
    "trainer.model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
