{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HCIg39APoFk"
   },
   "source": [
    "# Phase 3: Model Evaluation\n",
    "\n",
    "In the final phase, we will evaluate the performance of the fine-tuned Flan-T5 model. The evaluation involves comparing the summarization outputs of the fine-tuned model against the non-fine-tuned (base) model and the ground truth summaries. We will use ROUGE scores and qualitative assessments.\n",
    "\n",
    "## Steps:\n",
    "\n",
    "1. **Compute Evaluation Metrics:**\n",
    "    - **ROUGE Scores:** Measure ROUGE-1, ROUGE-2, and ROUGE-L to assess the quality of the generated summaries.\n",
    "\n",
    "2. **Generate and Compare Summaries:**\n",
    "    - **Qualitative Comparison:** Review summaries generated by the fine-tuned model, the base model, and compare them to the ground truth. Assess the quality and relevance of the generated summaries through manual inspection.\n",
    "    - Identify strengths and weaknesses to guide further improvements.\n",
    "\n",
    "This final phase validates the effectiveness of the fine-tuning process and highlights the improvements achieved in the model's summarization capabilities.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8569,
     "status": "ok",
     "timestamp": 1739714277534,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "CCo1ZsvEPsYh"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739714286038,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "cIBncdt5P2HQ",
    "outputId": "cda98280-3f86-40e3-dbd2-4789d2492222"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4-x8NejPqpj"
   },
   "source": [
    "### Load the original model and the fine-tuned model (with LoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8722,
     "status": "ok",
     "timestamp": 1739714297085,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "utmmOGtqP-kY",
    "outputId": "cfbc18b0-da68-4fa7-d900-5eca9a1e0080"
   },
   "outputs": [],
   "source": [
    "model_path=\"./peft_model_trained_google_flan_t5_base_dialogue_summarization \"\n",
    "\n",
    "model_name='google/flan-t5-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(base_model, model_path, is_trainable=False)\n",
    "peft_model = peft_model.to(device)\n",
    "peft_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3150,
     "status": "ok",
     "timestamp": 1739714300233,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "FR7yIxBYXSgh",
    "outputId": "dadcd8a9-637f-4d07-f090-eef562205e78"
   },
   "outputs": [],
   "source": [
    "# reload the base model\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "base_model = base_model.to(device)\n",
    "base_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aelzL-ZpR1oZ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8Xuru2IR39e"
   },
   "source": [
    "### Run the originl model and the fine-tuned model on the test set and save the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 867,
     "status": "ok",
     "timestamp": 1739714304920,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "Ybc1a86GP-h6"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "with open('data/dataset_t5_base.pkl', 'rb') as file:\n",
    "    dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PoYXwMDEX57r"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "model_predictions = pd.DataFrame([],columns=['ground_truth', 'base_model', 'fine_tuned_model'])\n",
    "\n",
    "# iterate ove the test set\n",
    "for i in tqdm(range(len(dataset['test']))):\n",
    "  input_ids = dataset['test']['input_ids'][i]\n",
    "  labels = dataset['test']['labels'][i]\n",
    "\n",
    "  # save the ground truth summary\n",
    "  model_predictions.loc[i,'ground_truth'] = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "  # use the base model to predict the summary\n",
    "  outputs_base_model = base_model.generate(\n",
    "        input_ids = torch.tensor(input_ids).unsqueeze(0).to(device),\n",
    "        generation_config=GenerationConfig(max_new_tokens=200)\n",
    "  )\n",
    "\n",
    "  # decode the output and put it in the dataframe\n",
    "  model_predictions.loc[i,'base_model'] = tokenizer.decode(outputs_base_model[0], skip_special_tokens=True)\n",
    "\n",
    "  # use the fine tuned model to predict the summary\n",
    "  outputs_peft_model = peft_model.generate(\n",
    "        input_ids = torch.tensor(input_ids).unsqueeze(0).to(device),\n",
    "        generation_config=GenerationConfig(max_new_tokens=200)\n",
    "  )\n",
    "\n",
    "  # decode the output and put it in the dataframe\n",
    "  model_predictions.loc[i,'fine_tuned_model'] = tokenizer.decode(outputs_peft_model[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byKx0Kv02xWX"
   },
   "outputs": [],
   "source": [
    "# save the predictions on the Test Set\n",
    "model_predictions.to_csv('data/model_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpKSY0IvRT28"
   },
   "source": [
    "### Compute the metric ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1739714310506,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "dVae0RI5CGcD"
   },
   "outputs": [],
   "source": [
    "# load the predictions of the test set\n",
    "model_predictions = pd.read_csv('data/model_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1739714332168,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "M4QmOvhbB82s"
   },
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "7fb6555be25f4d248696492d94a76991",
      "de3dd22c64574a28913add706bcf43ff",
      "cfda7a20ca3f44b9abb2f69072e65b2c",
      "0d5e775f30a4499ca6c1a33d49e590c2",
      "52d7182a3c194476b90fa7f0468ea1cc",
      "d4ac0f045e174362b1e5822bf10bddb3",
      "7a624b5d438c4168bc3559934875e996",
      "44669087829243e19c428157abc7dd58",
      "cdf842a7fecd4be3953acf4321735144",
      "cd689a2f359e4e8095bd7eb0d77d0291",
      "27dcd16290fc451fbfa469b0a1057227"
     ]
    },
    "executionInfo": {
     "elapsed": 5034,
     "status": "ok",
     "timestamp": 1739714345212,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "rFNKjXwrRXu9",
    "outputId": "d1266a71-e3ea-4dd3-c3ee-81b48c6c61b9"
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 9538,
     "status": "ok",
     "timestamp": 1739714624550,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "T_0rnmPBP-fW"
   },
   "outputs": [],
   "source": [
    "# compute the score for the base model and for the fine tuned model\n",
    "\n",
    "base_model_results = rouge.compute(\n",
    "    predictions=model_predictions['base_model'].to_list(),\n",
    "    references=model_predictions['ground_truth'].to_list(),\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "peft_model_results = rouge.compute(\n",
    "    predictions=model_predictions['fine_tuned_model'].to_list(),\n",
    "    references=model_predictions['ground_truth'].to_list(),\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1739714694322,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "Fong2eiCEd8K",
    "outputId": "5870cb72-c36c-41ed-ca49-7cb29ef628ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model scores:\n",
      "rouge1: 0.30828355875756297\n",
      "rouge2: 0.11217798863665049\n",
      "rougeL: 0.2579375123988149\n",
      "rougeLsum: 0.25795189499184956\n",
      "\n",
      " --------------- \n",
      "\n",
      "Fine-tuned Model scores:\n",
      "rouge1: 0.44021421624662826\n",
      "rouge2: 0.17529958772705015\n",
      "rougeL: 0.3560808212586427\n",
      "rougeLsum: 0.35632161056594747\n"
     ]
    }
   ],
   "source": [
    "print('Base Model scores:')\n",
    "for score in base_model_results:\n",
    "  print(f'{score}: {base_model_results[score]}')\n",
    "\n",
    "print('\\n --------------- \\n')\n",
    "\n",
    "print('Fine-tuned Model scores:')\n",
    "for score in peft_model_results:\n",
    "  print(f'{score}: {peft_model_results[score]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkAo2SbPFaZO"
   },
   "source": [
    "#### **We can notic how all the rouge scores improved with fine-tuning!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tg6yIMF1Psk3"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1739715213856,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "dbiwqNZ_PoFm"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# function to format the dialogue and remove the intro and summary prompt\n",
    "def format_dialogue(text):\n",
    "    # Remove the intro and summary prompt\n",
    "    text = re.sub(r\"^Here is a dialogue:\\s*\", \"\", text)  # Remove starting phrase\n",
    "    text = re.sub(r\"\\s*Write a short summary!$\", \"\", text)  # Remove ending phrase\n",
    "\n",
    "    # Insert a newline after each complete dialogue entry\n",
    "    formatted_text = re.sub(r\"(#Person\\d+#: [^#]+)\", r\"\\1\\n\", text).strip()\n",
    "\n",
    "    return formatted_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1739715776829,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "j0m5ntRtPzP-"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# select three random dialogues from the list\n",
    "indeces = random.sample(range(len(model_predictions)), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7EiSrUu3cXT"
   },
   "source": [
    "### Human evaluation of the predicted summary. Base model vs fine-tuned mdoel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ir_CblCFJVMk"
   },
   "source": [
    "#### **We can notice that the output of the fine-tuned model is mode extensive and is closer to the original summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1368,
     "status": "ok",
     "timestamp": 1739715779033,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "UpaJb8n9PzNH",
    "outputId": "39a16b9a-0135-4106-fb05-43035c29236e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Dialogue 574\n",
      "\n",
      "Original dialogue:\n",
      "\n",
      "#Person1#: Hi, I was wondering if I could get my test results from the other day. \n",
      "#Person2#: Yes, I would like to schedule an appointment for you to come in and talk with me. \n",
      "#Person1#: Is something wrong with me? \n",
      "#Person2#: No, sometimes the test results aren't clear and we need to do more to get a clearer picture. \n",
      "#Person1#: Can we talk about it now? \n",
      "#Person2#: I would if I knew anything for sure, but I want to take a second look. \n",
      "#Person1#: When can I come and see you? \n",
      "#Person2#: You can come in this afternoon. If you would feel better, bring your husband with you. \n",
      "#Person1#: Now I know that something bad is up! \n",
      "#Person2#: Just relax. We will talk about it this afternoon.\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth summary:\n",
      "\n",
      "#Person2# schedules an appointment with #Person1# and #Person1#'s husband. #Person1# is nervous to know the test results.\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Base model summary:\n",
      "\n",
      "Person1 wants to schedule an appointment for Person2 to come in and talk about the test results from the other day.\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Fine-tuned model summary:\n",
      "\n",
      "#Person1# wants to get the test results from the other day. #Person2# tells #Person1# they need to do more to get a clearer picture. #Person1# will come and talk about it this afternoon.\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Dialogue 1063\n",
      "\n",
      "Original dialogue:\n",
      "\n",
      "#Person1#: Say, Jim, how about going for a few beers after dinner? \n",
      "#Person2#: You know that is tempting but is really not good for our fitness. \n",
      "#Person1#: What do you mean? It will help us to relax. \n",
      "#Person2#: Do you really think so? I don't. It will just make us fat and act silly. Remember last time? \n",
      "#Person1#: I guess you are right. But what shall we do? I don't feel like sitting at home. \n",
      "#Person2#: I suggest a walk over to the gym where we can play singsong and meet some of our friends. \n",
      "#Person1#: That's a good idea. I hear Mary and Sally often go there to play pingpong. Perhaps we can make a foursome with them. \n",
      "#Person2#: Sounds great to me! If they are willing, we could ask them to go dancing with us. That is excellent exercise and fun, too. \n",
      "#Person1#: Good. Let's go now. \n",
      "#Person2#: All right.\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth summary:\n",
      "\n",
      "#Person1# feels bored at home and asks Jim go for a beer. Jim refuses and suggests going to the gym and meeting friends.\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Base model summary:\n",
      "\n",
      "Jim and Mary are going to the gym to play pingpong and ask Mary and Sally to go dancing.\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Fine-tuned model summary:\n",
      "\n",
      "Jim suggests going for a few beers after dinner but #Person1# thinks it's not good for their fitness. They decide to go to the gym and ask Mary and Sally to go dancing.\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Dialogue 522\n",
      "\n",
      "Original dialogue:\n",
      "\n",
      "#Person1#: Welcome, what would you like to order? \n",
      "#Person2#: I would like to get a double cheeseburger. \n",
      "#Person1#: Would you like everything on it? \n",
      "#Person2#: I would like everything on it, thank you. \n",
      "#Person1#: Do you want any fries? \n",
      "#Person2#: Let me get some large curly fries. \n",
      "#Person1#: Can I get you anything to drink? \n",
      "#Person2#: Sure, how about a medium Pepsi? \n",
      "#Person1#: Is that everything? \n",
      "#Person2#: That'll be all. Thanks. \n",
      "#Person1#: You're welcome, and your total is $ 5. 48. \n",
      "#Person2#: Thank you. Here you go.\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ground truth summary:\n",
      "\n",
      "#Person2# orders a $ 5. 48 meal including cheeseburger, fries, and Pepsi.\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Base model summary:\n",
      "\n",
      "Person1 wants to order a double cheeseburger.\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Fine-tuned model summary:\n",
      "\n",
      "#Person2# orders a double cheeseburger, fries, and Pepsi.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print the original dialogue and compare the grounf truth to the base model prediction and the fine-tuned model\n",
    "for idx in indeces:\n",
    "  print()\n",
    "  print('-'*150)\n",
    "  print('-'*150)\n",
    "  print()\n",
    "  print(f'Dialogue {idx}')\n",
    "  print()\n",
    "\n",
    "  original_dialogue = tokenizer.decode(dataset['test']['input_ids'][idx], skip_special_tokens=True)\n",
    "\n",
    "  print('Original dialogue:\\n')\n",
    "  print(format_dialogue(original_dialogue))\n",
    "\n",
    "  print()\n",
    "  print('-'*150)\n",
    "  print()\n",
    "\n",
    "  print('Ground truth summary:\\n')\n",
    "  print(model_predictions['ground_truth'][idx])\n",
    "\n",
    "  print()\n",
    "  print('-'*150)\n",
    "  print()\n",
    "\n",
    "  print('Base model summary:\\n')\n",
    "  print(model_predictions['base_model'][idx])\n",
    "\n",
    "  print()\n",
    "  print('-'*150)\n",
    "  print()\n",
    "\n",
    "  print('Fine-tuned model summary:\\n')\n",
    "  print(model_predictions['fine_tuned_model'][idx])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d5e775f30a4499ca6c1a33d49e590c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd689a2f359e4e8095bd7eb0d77d0291",
      "placeholder": "​",
      "style": "IPY_MODEL_27dcd16290fc451fbfa469b0a1057227",
      "value": " 6.27k/6.27k [00:00&lt;00:00, 193kB/s]"
     }
    },
    "27dcd16290fc451fbfa469b0a1057227": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44669087829243e19c428157abc7dd58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52d7182a3c194476b90fa7f0468ea1cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a624b5d438c4168bc3559934875e996": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fb6555be25f4d248696492d94a76991": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_de3dd22c64574a28913add706bcf43ff",
       "IPY_MODEL_cfda7a20ca3f44b9abb2f69072e65b2c",
       "IPY_MODEL_0d5e775f30a4499ca6c1a33d49e590c2"
      ],
      "layout": "IPY_MODEL_52d7182a3c194476b90fa7f0468ea1cc"
     }
    },
    "cd689a2f359e4e8095bd7eb0d77d0291": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdf842a7fecd4be3953acf4321735144": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cfda7a20ca3f44b9abb2f69072e65b2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44669087829243e19c428157abc7dd58",
      "max": 6270,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cdf842a7fecd4be3953acf4321735144",
      "value": 6270
     }
    },
    "d4ac0f045e174362b1e5822bf10bddb3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de3dd22c64574a28913add706bcf43ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4ac0f045e174362b1e5822bf10bddb3",
      "placeholder": "​",
      "style": "IPY_MODEL_7a624b5d438c4168bc3559934875e996",
      "value": "Downloading builder script: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
